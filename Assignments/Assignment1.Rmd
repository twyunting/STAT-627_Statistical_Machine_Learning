---
title: "STAT-627 Assignment 1"
author: "Yunting Chiu"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 1
Each exercise is worth 16 points.

## Exercise 1
For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.

Before we answering the questions, we should know a inflexible method is a simple method; a flexible method is a complex method.

The sample size n is extremely large, and the number of predictors p is small.
- **Better**. The large number of observations is better because we can know more about the detailed correlation between them. Also, the number of small predictors and large sample sizes may help to avoid a overfitting problem in a model.

The number of predictors p is extremely large, and the number of observations n is small.
- **Worse**. It is possible that not all predictors have a significant effect on the response variable. Overfitting and spurious correlation are phenomenons that affect data models with a large number of predictors, in which the data model performs well on training data but badly on test data. Plus, small sample sizes are not conducive to machine learning.

The relationship between the predictors and response is highly non-linear.
- **Better**. Because non-linearity allows predictors to be better fitted with the dependent variable.

The variance of the error terms, is extremely high.
- **Worse**. Because of the high variance, an algorithm may model the random noise training data rather than the expected outputs. High error terms would decrease the model's performance.

### References:
1. https://www.kdnuggets.com/2017/04/must-know-fewer-predictors-machine-learning-models.html
2. https://stats.stackexchange.com/questions/69237/flexible-and-inflexible-models-in-machine-learning
3. https://becominghuman.ai/machine-learning-bias-vs-variance-641f924e6c57

## Exercise 2
Describe the difference between a parametric and non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a noon-parametric approach)? What are its disadvantages?


## Exercise 5
This question should be answered using the `biomass` data set.
```{r}
library(tidyverse)
library(tidymodels)
data("biomass")
biomass %>%
  head()
```
a. Fit a multiple regression model to predict `HHV` using `carbon`, `hydrogen` and `oxygen`.
```{r}
# create a parsnip specification
linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm") -> lm_spec

# fit the model using tidymodel
lm_spec %>%
  fit(HHV ~ carbon + hydrogen + oxygen, data = biomass) -> lm_fit


lm_fit %>%
  pluck("fit") %>%
  summary()

# Another way to see the summary table
tidy(lm_fit)

# predict HHV variable
predict(lm_fit, new_data = biomass) 
```

b. Provide an interpretation of each coefficient in the model. Be careful, note the values `Cruise` is able to take.
```{r}
lm_fit %>%
  pluck("fit") %>%
  summary()
```

c. Write out the model in equation form.
$$
\hat{HHV} = 1.0456860 + 0.3478508carbon + 0.2430900hydrogen - 0.0003767oxygen
$$

d. For which the predictors can you reject the null hypothesis H0:$\beta j=0$?

Hypothesis test: H0: $\beta j=0$ vs Ha: $\beta j \neq{0}$

The p-value of $b_1$ and $b_2$ is less than 2e-16 and 0.0000986, so we have evidence to reject the null hypothesis in favor of the alternative hypothesis, meaning that $b_1$ and $b_2$ are not equal to 0. Thus, predictor `carbon` and `hydrogen` can be rejected the null hypothesis. 

e. On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome.

Based on the result from 5d, we consider removing the 

f. How well do the models in (a) and (e) fit the data? How big was the effect of removing the predictor?