---
title: "STAT-627 Assignment 4"
author: "Yunting Chiu"
date: "`r Sys.Date()`"
output:
  html_document: 
    number_sections: yes
    theme: cerulean
    highlight: kate
urlcolor: blue
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(ggthemes)
```

In this assignment, I will be using [Tidymodels](https://www.tidymodels.org/) instead of base R.

# Exercise 1 (10 points)

Explain the assumptions we are making when performing Principle Component Analysis (PCA). What happens when these assumptions are violated?

## The assumptions of PCA
1. Linearity: The data set is assumed to be linear combinations of the variables.

2. Interval-level measurement: All variables should be assessed on an interval or ratio level of measurement.

3. Random sampling: 

Unlike factor analysis, PCA assumes that there is no unique variance and that total variance equals common variance.

# Exercise 2 (10 points)

Answer the following questions regarding Principle Component Analysis.

- Is it important to standardize before applying PCA?

- Should one remove highly correlated variables before doing PCA?

- What will happen when eigenvalues are roughly equal?
- Can PCA be used to reduce the dimensionality of a highly nonlinear data set?

# Exercise 3 (10 points)

You will in this exercise explore a data set using PCA. The data comes from the [#tidytuesday project](https://github.com/rfordatascience/tidytuesday) and is about [Student Loan Payments](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-11-26).

Load in the data using the following script.
```{r}
loans <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-26/loans.csv") %>%
  select(-agency_name, -added) %>%
  drop_na()
```

a.  Use the `prcomp()` function to perform PCA on the loans data set. Set `scale. = TRUE` to perform scaling. What results are contained in this object? (hint: use the `names()` function)

`loans` data set has the following variables
```{r}
names(loans)
```

Make sure we need to remove all non-numeric columns in advance. Sure, we can go ahead.
```{r}
str(loans)
```

Performing PCA on the `loans` data set
```{r}
loans_pca <- prcomp(~., data = loans, scale. = TRUE) 
loans_pca
```


b. Calculate the amount of variance explained by each principal component. (hint: look at `?broom::tidy.prcomp`)

Standard deviation = square root of the variance, so the variance by each principal component will be:
```{r}
loans_pca %>%
  tidy(matrix = "pcs") %>%
  mutate(Variance = (std.dev)^2) %>%
  select(PC, Variance)
```

c. Use the `tidy()` function to extract the **loadings**. Which variable contributed most to the first principle component? Second Component?

- `starting` contributes the most in PC1.
- `quarter` contributes the most in PC2.
```{r}
loans_pca %>%
  tidy(matrix = "loadings") %>%
  filter(PC == 1 | PC == 2) %>%
  ggplot(aes(value, column)) +
  geom_col() +
  facet_wrap(~PC) +
  theme_bw()
```


d. Use the `augment()` function to get back the transformation and create a scatter plot of any two components of your choice.

The fitted PC1 and PC2 coordinates for each quarter of the year are shown below.
```{r}
augment(loans_pca, newdata = loans) %>%
  ggplot(aes(x = .fittedPC1, y = .fittedPC2, color = factor(quarter))) +
  geom_point() +
  theme_bw() +
  labs(color = "Quarter") 
```


# Exercise 4 (15 points)

In this exercise, you are tasked to predict the weight of an animal in a zoo, based on which words are used to describe it. The `animals` data set can be downloaded [here](data/animals.csv).

Read the data set. We can see there are 801 variables with 479 observations!!!
```{r}
animals <- read_csv("./data/animals.csv") %>%
  filter(!is.na(weight))
dim(animals)
# str(animals) # all variables are numerical
```

This data set contains 801 variables. The first variable `weight` is the natural log of the mean weight of the animal. The remaining variables are named `tf_*` which shows how many times the word `*` appears in the description of the animal.

Use {tidymodels} to set up a workflow to train a PC regression. We can do this by specifying a **linear regression model**, and create a preprocessor recipe with {recipes} that applies PCA transformation on the predictors using `step_pca()`. Use the `threshold` argument in `step_pca()` to only keep the principal components that explain 90% of the variance.

Setting a seed and splitting the data to the training and testing sets
```{r}
set.seed(1234)
animals_split <- initial_split(animals, strata = "weight")
animals_train <- training(animals_split)
animals_test <- testing(animals_split)
```

Customize a recipe for the question
```{r, message=FALSE, warning=FALSE}
rec_spec <- recipe(weight ~., data = animals_train) %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), threshold = 0.9)
rec_spec 
```

Construct a linear regression specification
```{r}
lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")
lm_spec
```

Construct the model workflow
```{r}
pcr_wf <- workflow() %>%
  add_recipe(rec_spec) %>%
  add_model(lm_spec)
pcr_wf
```

Fit the model
```{r}
pcr_fit <- fit(pcr_wf, data = animals_train)
```


How well does this model perform on the testing data set?

Lower value of RMSE indicates a better fit. In the initial stage, we want to keep the principal components that explain 90% of the variance so we set `threshold = 0.9` in `step_pca()`. The algorithm will generate enough components to capture 90 % of the variability in the variables. Because we have 90% variables, the rmse will be small when compared to `threshold = 0.1`. 
```{r}
augment(pcr_fit, new_data = animals_test) %>%
  rmse(truth = weight, estimate = .pred) # root mean squared error
```

Because Principal Component Analysis is a linear method, the blue line can help us read the plot more easily. As of now, the `animals` data set contains 800 predictors, and PCR is effective at reducing the dimensionality of large data sets. The model has a good fit because the majority of the fitted values are between -5 and 5.
```{r}
augment(pcr_fit, new_data = animals_test) %>%
  ggplot(aes(weight, .pred)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "blue") +
  coord_fixed() +
  theme_bw()
```

# Exercise 5 (10 points)

For part (a) through (c) indicate which of the statements are correct. Justify your answers.

a. The lasso, relative to least squares, is:
    1. More flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.
    2. More flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias.
    3. Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.
    4. Less flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias.
    
## The lasso (L1 Regularization), relative to least squares is

**3** is correct. Compared to least squares models, the lasso is a restrictive model. Lasso regression can shrunk coefficients to 0 exactly (unless $\lambda = \infty$). In comparison to least squares, it penalizes the coefficients of non-essential variables to produce a model with a lower variance and higher bias.

## The ridge (L2 Regularization), relative to least squares is

b. Repeat (a) for ridge regression relative to least squares.

**3** is correct. Because coefficients tend towards zero, variance decreases and bias increases, causing ridge regression less flexible than least squares regression. As the coefficient estimates shrink, we can obtain a relatively better MSE in ridge regression. The least squares coefficient results in a larger variance value. Ridge regression, on the other hand, can still perform well by trading off a increase in bias and reduce in variance.

## The non-linear methods, relative to least squares is

c. Repeat (a) for non-linear methods relative to least squares.

**2** is correct. Non-linear models have more flexibility and less bias than least squares models. Non-linear models perform better when the linearity assumption is violated. Due to Non-linear models more sensitive fits to the underlying data, these approaches will have higher variation and will require a substantial reduction in bias to work well.

# Exercise 6 (10 points)

Suppose we estimate the regression coefficients in a linear regression model by minimizing
$$
\sum_{i=1}^n \left( y_i - \beta_0 - \sum^p_{j=1}\beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^p \beta_j^2
$$

for a particular value of $\lambda$. For part (a) through (c) indicate which of the statements are correct. Justify your answers.

a. As we increase $\lambda$ from 0, the training RSS will:
    - Increase initially, and then eventually start decreasing in an inverted U shape.
    - Decrease initially, and then eventually start increasing in a U shape.
    - Steadily increase.
    - Steadily decrease.
    - Remain constant.
b. Repeat (a) for test RSS.
c. Repeat (a) for variance.
d. Repeat (a) for squared bias.
e. Repeat (a) for the irreducible error.

# Exercise 7 (15 points)

In this exercise, you are tasked to predict the weight of an animal in a zoo, based on which words are used to describe it. The `animals` data set can be downloaded [here](data/animals.csv).

This data set contains 801 variables. The first variable `weight` is the natural log of the mean weight of the animal. The remaining variables are named `tf_*` which shows how many times the word `*` appears in the description of the animal.

(a) Fit a **lasso regression model** to predict `weight` based on all the other variables.

(b) Use the **tune** package to perform hyperparameter tuning to select the best value of $\lambda$. Use 10 bootstraps as the `resamples` data set.

(c) How well does this model perform on the testing data set?

## Lasso Regression

Recap the data set
```{r}
animals %>%
  head()
```

`mixture = 1` indicates that it is a lasso model.
```{r}
# engine specification
lasso_spec <- linear_reg(mixture = 1, penalty = tune()) %>%
  set_mode("regression") %>%
  set_engine("glmnet")
```

Put in our ingredients and get a recipe. Because ridge regression is scale sensitive, we must ensure that the variables are on the same scale by using `step_normalize(all_predictors())`.
```{r, message=FALSE}
# customize a recipe
lasso_rec <- recipe(weight ~., data = animals_train) %>%
  step_normalize(all_predictors()) %>%
  step_zv(all_predictors()) 
```

## Workflow
```{r}
lasso_wf <- workflow() %>%
  add_model(lasso_spec) %>%
  add_recipe(lasso_rec)
```

Create a bootstrap term in order to use in the following `tune_grid()` session. We use 10 bootstraps.
```{r}
set.seed(4321)
animals_boots <- bootstraps(animals_train, strata = weight, time = 10)
animals_boots$splits
```

Regularly predict the penalty 50 times using regular grids, with the penalty range limited to $10^{-5}$ to $0$. Note, these are in transformed units, the default transformation is $log10$.
```{r}
penalty_grid <- grid_regular(penalty(range = c(-5, 0)), levels = 50)
```

## Tune
```{r, warning=FALSE}
tune_res <- tune_grid(object = lasso_wf, resamples = animals_boots,
                      grid = penalty_grid)
tune_res
```

Display the each penalty on rmse and rsq, respectively.
```{r}
tune_res %>%
  collect_metrics()
```
Display the best five rmse value of penalty
```{r}
tune_res %>%
  show_best(metric = "rmse")
```

We can see that if the amount of regularization is close to 0.25, the rmse is low and the rsq is high, on average. Thus, the best hyperparameter of this model should be here.
```{r}
tune_res %>%
  autoplot() +
  geom_vline(xintercept = 0.2442053, color = "red") 
```

## Best Hyperparameter

The best value of $\lambda$ is 0.244.
```{r}
best_rmse <- select_best(tune_res, metric = "rmse")
best_rmse
```

```{r}
lasso_final <- finalize_workflow(lasso_wf, best_rmse)
```

```{r}
lasso_final_fit <- fit(lasso_final, data = animals_train) 
```

## Peformance

Fit a lasso regression model to predict weight based on all the other variables. With the rmse value, we can conclude that the model performs mediocrity. However, we can carry out additional comparisons, such as canceling the penalty term in the model, to determine whether the good performance is due to hyperparameters or the model itself.
```{r}
augment(lasso_final_fit, new_data = animals_test) %>%
  rmse(truth = weight, estimate = .pred)
```
## Visualization

```{r}
augment(lasso_final_fit, new_data = animals_test) %>%
  ggplot(aes(weight, .pred)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point() +
  theme_bw()
```

The `weight` range is from -8.111728 to 10.491274, and based on the plot above, we can conclude that the model does not work well; tuning $\lambda$ appears to have no obvious benefit in the model.
```{r}
animals %>%
  select(weight) %>%
  range()
```

# References
- https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a
- https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f
- https://stats.idre.ucla.edu/spss/seminars/efa-spss/
- https://clauswilke.com/blog/2020/09/07/pca-tidyverse-style/
- https://medium.com/analytics-vidhya/principal-component-analysis-too-many-variables-here-73dddec6b53d



