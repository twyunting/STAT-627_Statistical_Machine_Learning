---
title: "Lab 04 - Week 2 Wednesday"
author: "Yunting Chiu"
date: "`r Sys.Date()`"
output:
  html_document: 
    theme: cerulean
    highlight: zenburn
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We will be using the add-on package [discrim](https://discrim.tidymodels.org/) to access functions to perform discriminant analysis models with `parsnip` and the `klaR` package to perform the QDA calculations. if you haven't already got it installed run

Create a test-train `rsplit` object of `mlc_churn` using `initial_split()`. Use the arguments to set the proportions of the training data to be 80%. Stratify the sampling according to the `churn` variable.

Do the following tasks for LDA, QDA and KNN model.

# Setup
```{r}
# install.packages(c("discrim", "klaR"))
library(tidyverse)
library(tidymodels)
library(discrim)
data("mlc_churn")
head(mlc_churn)
```
Splitting the data to training and testing sets.
```{r}
set.seed(1234)
mlc_split <- initial_split(mlc_churn, prop = 0.8, strata = churn)
mlc_split

mlc_training <- training(mlc_split)
mlc_testing <- testing(mlc_split)

# model formula
churn_formula <- churn ~ number_vmail_messages + total_intl_minutes + total_intl_calls + total_intl_charge + number_customer_service_calls
```

# LDA (Linear Discriminant Analysis)
a. Fit a classification model. Use `number_vmail_messages`, `total_intl_minutes`, `total_intl_calls`, `total_intl_charge`, `number_customer_service_calls` as predictors. Remember to fit the model only using the training data set.
```{r}
lda_spec <- discrim_linear() %>%
  set_mode("classification") %>%
  set_engine("MASS") # the default is "MASS", otherwise is "mda"
```
Fit the LDA model
```{r}
lda_fit <- fit(lda_spec, churn_formula, data = mlc_training)
lda_fit
```
The summary shows that our training prior probabilities of customer churn are 0.14 says **Yes** and 0.86 says **No**. The group means indicate the mean of each variable in each group. Plus, the coefficients of linear discriminants shows the linear combination of predictor variables that are used to form the LDA decision rule. For instance, `LD1 = 0.02711856*number_vmail_messages + 1.00746332*total_intl_minutes + 0.08589699*total_intl_calls - 4.07968773*total_intl_charge - 0.69807223*number_customer_service_calls`. Because there are only two response classes in this model, there will be only one set of coefficients (LD1).

b. Inspect the model with `summary()` and `tidy()`. How good are the variables we have chosen?

We can be using `summary(lda_fit$fit$means)` to see each mean of predictors, the outcome looks not bad.
```{r}
summary(lda_fit$fit$means)
```
`tidy()` can not works
```{r, error=TRUE}
tidy(lda_fit)
```

c. Predict values for the testing data set.

See the probability of answering **Yes** or **No**. We only show the first six rows to ensure that the output is clear, but you can manually remove `head()` to see the all results. All datasets will be still using `head()` in order to compress the outputs.
```{r}
predict(lda_fit, new_data = mlc_testing, type = "prob") %>%
  head()
```
Using `augment()` is the simplest way to incorporate the prediction into an existing data frame.
```{r}
augment(lda_fit, new_data = mlc_testing) -> ldaPredDF
head(ldaPredDF)
```

d. Use `conf_mat()` to construct a confusion matrix. Does the confusion matrix look good?

The up-left area represents true negative, and the down-right area represents true positive; these two values are a leading indicator for determining whether the model is good or not. The true negative is 12, which greater then the false positive 5, and the true positive is 853, which is greater than false negative 129. Thus, the confusion matrix shows the model has a good prediction.
```{r}
ldaPredDF %>%
  conf_mat(estimate = .pred_class, truth = churn)
```
The linear discriminant analysis model has 87 % accuracy for predicting the customer churn.
```{r}
ldaPredDF %>%
accuracy(truth = churn, estimate = .pred_class)
```

# QDA (Quadratic Discriminant Analysis)
a. Fit a classification model. Use `number_vmail_messages`, `total_intl_minutes`, `total_intl_calls`, `total_intl_charge`, `number_customer_service_calls` as predictors. Remember to fit the model only using the training data set.
```{r}
qda_spec <- discrim_regularized(frac_common_cov = 0, frac_identity = 0) %>%
  set_mode("classification") %>%
  set_engine("klaR")
```
Fit the QDA model
```{r}
qda_fit <- fit(qda_spec, formula = churn_formula, data = mlc_training)
qda_fit
```
The fitting time 159ms. We can find the prior probabilities and group means in this table. 


b. Inspect the model with `summary()` and `tidy()`. How good are the variables we have chosen?
```{r}
summary(qda_fit$fit)
```
`tidy()` can not works
```{r, error=TRUE}
tidy(qda_fit)
```
To see more relationship between these predictors. We can also see the "Yes" covariances divided by "No" covariances by using the programming skill.
```{r}
qda_fit$fit$covariances[,, "yes"] / qda_fit$fit$covariances[,, "no"]
```
c. Predict values for the testing data set.
```{r}
predict(qda_fit, new_data = mlc_testing, type = "prob") %>%
  head()

augment(qda_fit, new_data = mlc_testing) -> qdaPredDF
qdaPredDF %>%
  head()
```

d. Use `conf_mat()` to construct a confusion matrix. Does the confusion matrix look good?
The up-left area represents true negative, and the down-right area represents true positive; these two values are a leading indicator for determining whether the model is good or not. The true negative is 27, which greater then the false positive 17, and the true positive is 841, which is greater than false negative 114. Thus, the confusion matrix shows the model has a good prediction.
```{r}
qdaPredDF %>%
  conf_mat(estimate = .pred_class, truth = churn)
```
The quadratic discriminant analysis model has 87 % accuracy for predicting the customer churn.
```{r}
qdaPredDF %>%
accuracy(truth = churn, estimate = .pred_class)
```

# KNN (k-Nearest Neighbors Algorithm)
a. Fit a classification model. Use `number_vmail_messages`, `total_intl_minutes`, `total_intl_calls`, `total_intl_charge`, `number_customer_service_calls` as predictors. Remember to fit the model only using the training data set.
```{r}
knn_spec <- nearest_neighbor(neighbors = 5) %>% # default k is 5
  set_mode("classification") %>%
  set_engine("kknn")

knn_fit <- fit(knn_spec, data = mlc_training, formula = churn_formula)
knn_fit
```

b. Inspect the model with `summary()` and `tidy()`. How good are the variables we have chosen?

The misclassification is the percentage of classifications that are incorrect. The minimal misclassification is 0.15, meaning that the predictor variables are not bad.
```{r}
summary(knn_fit$fit)
```
`tidy()` can not works
```{r, error=TRUE}
tidy(knn_fit)
```

c. Predict values for the testing data set.
```{r}
augment(knn_fit, new_data = mlc_testing) -> knnPredDF
knnPredDF %>%
  head()
```

d. Use `conf_mat()` to construct a confusion matrix. Does the confusion matrix look good?

The up-left area represents true negative, and the down-right area represents true positive; these two values are a leading indicator for determining whether the model is good or not. The true negative is 23, which less then the false positive 49, and the true positive is 809, which is greater than false negative 118. Thus, the confusion matrix shows the model has a good prediction, maybe.
```{r}
knnPredDF %>%
  conf_mat(estimate = .pred_class, truth = churn)
```

The KNN model with 5 neighbors has 83 % accuracy for predicting the customer churn.
```{r}
knnPredDF %>%
accuracy(truth = churn, estimate = .pred_class)
```

# References
- http://www.sthda.com/english/articles/36-classification-methods-essentials/146-discriminant-analysis-essentials-in-r/
- http://uc-r.github.io/discriminant_analysis
- https://datascienceplus.com/how-to-perform-logistic-regression-lda-qda-in-r/
